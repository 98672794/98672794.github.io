{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Telegramç«¯æ­¥é©Ÿ https://pixnashpython.pixnet.net/blog/post/32391757-%E3%80%90telegram-api%E3%80%91python\n",
    "'''\n",
    "æ­¥é©Ÿä¸€ï¼šåœ¨Telegramæœå°‹æ¬„è¼¸å…¥BotFatherä¸¦æ‰“é–‹\n",
    "\n",
    "æ­¥é©ŸäºŒï¼šè¼¸å…¥ /newbot\n",
    "\n",
    "æ­¥é©Ÿä¸‰ï¼šè¼¸å…¥æ©Ÿå™¨äººé¡¯ç¤ºåç¨±\n",
    "\n",
    "æ­¥é©Ÿå››ï¼šè¼¸å…¥æ©Ÿå™¨äººå¯æœå°‹åç¨±\n",
    "\n",
    "æ­¥é©Ÿäº”ï¼šå–å¾—TOKENè¤‡è£½èµ·ä¾†(PYTHONç”¨)\n",
    "'''\n",
    "#########\n",
    "# https://www.freecodecamp.org/chinese/news/how-to-create-a-telegram-bot-using-python/\n",
    "!pip install pyTelegramBotAPI\n",
    "\n",
    "\n",
    "# è‡ªå‹•ç²å–å·¥ä½œè³‡æ–™\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 28 ç‰ˆ $$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# https://chatgpt.com/share/ebfd449c-14c5-4dcc-a669-40d8f16f30c1\n",
    "\n",
    "# è‡ªå‹•ç²å–å·¥ä½œè³‡æ–™\n",
    "# chatgpt monica\n",
    "# https://chat.openai.com/share/57c5b600-4c6a-40d2-b140-dd4761d6e5cd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time  # æ–°å¢æ­¤è¡Œï¼Œç”¨æ–¼æ§åˆ¶è«‹æ±‚é–“çš„ç­‰å¾…æ™‚é–“\n",
    "\n",
    "\n",
    "# TG\n",
    "import os\n",
    "import re\n",
    "import telebot\n",
    "from google.colab import userdata\n",
    "\n",
    "\n",
    "# æµè€é—†ç”¨\n",
    "from selenium.common.exceptions import ElementNotInteractableException, NoSuchElementException\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class JobScraper:\n",
    "    # selenium setting\n",
    "    def __init__(self, keyword):\n",
    "        self.keyword = keyword\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument('--headless')\n",
    "        self.chrome_options.add_argument('--no-sandbox')\n",
    "        self.chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        self.chrome_options.add_argument('--disable-gpu')\n",
    "        self.driver = webdriver.Chrome(options=self.chrome_options)\n",
    "\n",
    "\n",
    "    ### æ‰¾å·¥ä½œ æ‰¾å·¥ä½œ æ‰¾å·¥ä½œ æ‰¾å·¥ä½œ æ‰¾å·¥ä½œ ### \n",
    "    def _è‡ªå‹•ç²å–é¦™æ¸¯å‹å·¥è™•å·¥ä½œè³‡æ–™(self):\n",
    "        driver = webdriver.Chrome(options=self.chrome_options)\n",
    "        driver.get(\"https://www1.jobs.gov.hk/0/tc/jobseeker/jobsearch/joblist/\")\n",
    "\n",
    "        # å¡«å¯«é—œéµå­—ä¸¦é»æ“Šæœå°‹æŒ‰éˆ•\n",
    "        search_box = driver.find_element(By.ID, \"simp_searchKeyword\")\n",
    "        search_box.send_keys(self.keyword)\n",
    "        search_button = driver.find_element(By.ID, \"btnSearch\")\n",
    "        search_button.click()\n",
    "\n",
    "        é¡¯ç¸½æ–™æ•¸ = 0\n",
    "        _æ¯é é‡ = 20\n",
    "        allå·¥æ–™ = []\n",
    "\n",
    "        while True:\n",
    "            # ç­‰å¾…æœå°‹çµæœåŠ è¼‰å®Œæˆ\n",
    "            WebDriverWait(driver, 10).until(EC.url_changes(\"https://www1.jobs.gov.hk/0/tc/jobseeker/jobsearch/joblist/\"))\n",
    "\n",
    "            # ç²å–æœå°‹çµæœçš„HTML\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # è§£æHTMLä¸¦æå–å·¥ä½œè³‡æ–™\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "            content_div = soup.find(\"div\", id=\"content-innerdiv\")\n",
    "            job_listings = content_div.find_all(\"tr\", class_=\"bg-white\")\n",
    "\n",
    "            # å–å¾—è³‡æ–™ç¸½æ•¸\n",
    "            if é¡¯ç¸½æ–™æ•¸ == 0:\n",
    "                total_jobs = soup.find(\"div\", class_=\"py-2 d-lg-none\").strong.text.strip()\n",
    "                print(\"ç¸½å…±è³‡æ–™æ•¸:\", total_jobs)\n",
    "                é¡¯ç¸½æ–™æ•¸=1\n",
    "\n",
    "                ç¸½å…±è³‡æ–™æ•¸ = f'ç¸½å…±è³‡æ–™æ•¸: {total_jobs}\\n *** è³‡æ–™ä¾†æº:é¦™æ¸¯å‹å·¥è™• ***\\n\\n'\n",
    "\n",
    "            for job in job_listings:\n",
    "                è·ä½ = job.find(\"span\").find(\"span\").text.strip()\n",
    "                åˆŠæ—¥ = job.find_next(\"div\", class_=\"col mb-2 mb-lg-0\").span.text.strip()\n",
    "                è–ªé…¬ = job.find_all(\"div\", class_=\"col mb-2 mb-lg-0\")[1].span.text.strip()\n",
    "                åœ°é» = job.find_all(\"div\", class_=\"col mb-2 mb-lg-0\")[2].span.text.strip()\n",
    "                ç¶“é©— = job.find_all(\"div\", class_=\"col mb-2 mb-lg-0\")[3].span.text.strip()\n",
    "                ç¨‹åº¦ = job.find_all(\"div\", class_=\"col mb-2 mb-lg-0\")[4].span.text.strip()\n",
    "                ç¶²å€ = \"https://www1.jobs.gov.hk\" + job.find_next(\"a\")[\"href\"]\n",
    "\n",
    "                å·¥æ–™ = f'{è·ä½}\\n{è–ªé…¬}\\n{åœ°é»}\\n{ç¶“é©—}\\n{ç¨‹åº¦}\\n{ç¶²å€}\\n$$$$ $$$$'\n",
    "                allå·¥æ–™.append(å·¥æ–™)\n",
    "\n",
    "            # é»æ“Šä¸‹ä¸€é æŒ‰éˆ•\n",
    "            if int(total_jobs) > _æ¯é é‡:\n",
    "                # é»æ“Šä¸‹ä¸€é æŒ‰éˆ•\n",
    "                next_page_button = driver.find_element(By.XPATH, '//*[@id=\"content-innerdiv\"]/div[4]/div/a[3]')\n",
    "                next_page_button.click()\n",
    "                _æ¯é é‡ += 20\n",
    "            else:\n",
    "\n",
    "              allå·¥æ–™.append(ç¸½å…±è³‡æ–™æ•¸)\n",
    "              break\n",
    "\n",
    "        # é—œé–‰ç€è¦½å™¨\n",
    "        driver.quit()\n",
    "\n",
    "        return allå·¥æ–™\n",
    "\n",
    "\n",
    "    # è‡ªå‹•ç²å–é¦™æ¸¯å‹å·¥è™•å·¥ä½œè³‡æ–™ \\\n",
    "    def _çˆ¬å–CareerJetHKå…§å®¹(self):\n",
    "        driver = webdriver.Chrome(options=self.chrome_options)\n",
    "        allå·¥æ–™ = []\n",
    "        page_number = 1\n",
    "\n",
    "        while True:\n",
    "            # è¨­ç½®ç•¶å‰é é¢çš„URL\n",
    "            url = f\"https://www.careerjet.com.hk/%E6%8B%9B%E8%81%98?s={self.keyword}&l=%E9%A6%99%E6%B8%AF&p={page_number}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # ç­‰å¾…æœå°‹çµæœåŠ è¼‰å®Œæˆ\n",
    "            try:\n",
    "                WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '//*[@id=\"search-content\"]/ul'))\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"æœå°‹çµæœé é¢åŠ è¼‰å¤±æ•—æˆ–ç„¡è³‡æ–™: {e}\")\n",
    "                break\n",
    "\n",
    "            # å–å¾—æœå°‹çµæœçš„HTML\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            # æŠ“å–æŒ‡å®šå€å¡Šçš„å…§å®¹\n",
    "            job_listings = soup.select('#search-content > ul > li')\n",
    "\n",
    "            # å¦‚æœç•¶å‰é æ²’æœ‰è³‡æ–™ï¼Œå‰‡çµæŸçˆ¬å–\n",
    "            if not job_listings:\n",
    "                print(\"å·²ç„¡æ›´å¤šè³‡æ–™ï¼ŒçµæŸçˆ¬å–ã€‚\")\n",
    "                break\n",
    "\n",
    "            for job in job_listings:\n",
    "                try:\n",
    "                    # å…§æ–‡ç¶²å€\n",
    "                    content_url = job.find('h2').find('a')['href']\n",
    "                    å…§æ–‡ç¶²å€ = \"https://www.careerjet.com.hk\" + content_url\n",
    "                    # å·¥ä½œæ¨™é¡Œ\n",
    "                    å·¥ä½œæ¨™é¡Œ = job.find('h2').find('a').text.strip()\n",
    "                    # å…¬å¸åç¨±\n",
    "                    å…¬å¸åç¨± = job.find('p').text.strip()\n",
    "                    # å…¬å¸åœ°å€\n",
    "                    å…¬å¸åœ°å€ = job.find_all('ul')[1].find('li').text.strip()\n",
    "                    # ç°¡ä»‹\n",
    "                    ç°¡ä»‹ = job.find('div').text.strip()\n",
    "\n",
    "                    # èª¿æ•´æ’åˆ—é †åº\n",
    "                    content_data = {\n",
    "                        \"å·¥ä½œæ¨™é¡Œ\": å·¥ä½œæ¨™é¡Œ,\n",
    "                        \"å…¬å¸åç¨±\": å…¬å¸åç¨±,\n",
    "                        \"å…¬å¸åœ°å€\": å…¬å¸åœ°å€,\n",
    "                        \"ç°¡ä»‹\": ç°¡ä»‹,\n",
    "                        \"å…§æ–‡ç¶²å€\": å…§æ–‡ç¶²å€\n",
    "                    }\n",
    "                    å·¥æ–™ = f'{å…¬å¸åç¨±}\\n{å·¥ä½œæ¨™é¡Œ}\\n{å…¬å¸åœ°å€}\\n{ç°¡ä»‹}\\n{å…§æ–‡ç¶²å€}\\n$$$$ $$$$'\n",
    "\n",
    "                    allå·¥æ–™.append(å·¥æ–™)\n",
    "                except Exception as e:\n",
    "                    print(\"éŒ¯èª¤:\", e)\n",
    "                    continue\n",
    "            #print(f\"ç¬¬{page_number}é è³‡æ–™å·²æˆåŠŸæŠ“å–ã€‚\")\n",
    "            page_number += 1  # è·³åˆ°ä¸‹ä¸€é \n",
    "        # é—œé–‰ç€è¦½å™¨\n",
    "        driver.quit()\n",
    "\n",
    "        allå·¥æ–™.append(f'ç¸½å…±è³‡æ–™æ•¸: {len(allå·¥æ–™)}\\n *** è³‡æ–™ä¾†æº:careerjet.com.hk ***\\n\\n')\n",
    "\n",
    "        return allå·¥æ–™\n",
    "    # è‡ªå‹•ç²å–careerjet.com.hkå·¥ä½œè³‡æ–™ \\\n",
    "\n",
    "\n",
    "    def ç²å–æ‰€æœ‰å·¥ä½œè³‡æ–™(self):\n",
    "        å›1 = self._è‡ªå‹•ç²å–é¦™æ¸¯å‹å·¥è™•å·¥ä½œè³‡æ–™()\n",
    "        å›2 = self._çˆ¬å–CareerJetHKå…§å®¹()\n",
    "        return å›1 + å›2\n",
    "    ### æ‰¾å·¥ä½œ æ‰¾å·¥ä½œ æ‰¾å·¥ä½œ æ‰¾å·¥ä½œ æ‰¾å·¥ä½œ ### \n",
    "\n",
    "\n",
    "\n",
    "    ### æ‰¾è€é—† æ‰¾è€é—† æ‰¾è€é—† æ‰¾è€é—† æ‰¾è€é—† ### \n",
    "    # https://chatgpt.com/share/dd6041da-f9d8-464b-a44e-6d7ccb3adee4\n",
    "    # https://chatgpt.com/share/0fcb7dec-9243-428c-8ae5-3b2531aef601\n",
    "    def _æµè¦è«‹äººçš„è€é—†(self):\n",
    "        self.driver.get(\"https://www1.jobs.gov.hk/0/tc/jobseeker/jobsearch/joblist/\")\n",
    "\n",
    "        # å¡«å¯«é—œéµå­—ä¸¦é»æ“Šæœå°‹æŒ‰éˆ•\n",
    "        search_box = self.driver.find_element(By.XPATH, '//*[@id=\"simp_searchKeyword\"]')\n",
    "        search_box.send_keys(self.keyword)\n",
    "        search_button = self.driver.find_element(By.XPATH, '//*[@id=\"btnSearch\"]')\n",
    "        search_button.click()\n",
    "\n",
    "        job_links = []\n",
    "        while True:\n",
    "            # ç­‰å¾…é é¢åŠ è¼‰å®Œæˆ\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"job_list_table\"]'))\n",
    "            )\n",
    "\n",
    "            # ç²å–æœå°‹çµæœçš„HTML\n",
    "            page_source = self.driver.page_source\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            # æå–æ¯å€‹è·ä½çš„é€£çµ\n",
    "            job_rows = soup.find('table', id=\"job_list_table\").find_all('tr')\n",
    "            for row in job_rows:\n",
    "                link_tag = row.find('a', id=re.compile(r'\\d+_orderNo_hyper'))\n",
    "                if link_tag:\n",
    "                    link = link_tag.get('href')\n",
    "                    job_links.append(\"https://www1.jobs.gov.hk\" + link)\n",
    "                else:\n",
    "                    print(\"æœªæ‰¾åˆ°è·ä½é€£çµï¼Œç•¥éè©²è¡Œã€‚\")\n",
    "\n",
    "            # æª¢æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é æŒ‰éˆ•ï¼Œä¸¦å˜—è©¦é»æ“Š\n",
    "            try:\n",
    "                next_button_element = self.driver.find_element(By.XPATH, '//*[@id=\"content-innerdiv\"]/div[4]/div/a[3]')\n",
    "                if next_button_element.is_displayed() and next_button_element.is_enabled():\n",
    "                    next_button_element.click()\n",
    "                    time.sleep(2)  # ç¢ºä¿é é¢å®Œå…¨åŠ è¼‰\n",
    "                else:\n",
    "                    print(\"ä¸‹ä¸€é æŒ‰éˆ•ä¸å¯é»æ“Šï¼ŒçµæŸæŠ“å–ã€‚\")\n",
    "                    break\n",
    "            except (ElementNotInteractableException, NoSuchElementException):\n",
    "                print(\"æœªæ‰¾åˆ°ä¸‹ä¸€é æŒ‰éˆ•æˆ–æŒ‰éˆ•ç„¡æ³•äº’å‹•ï¼ŒçµæŸæŠ“å–ã€‚\")\n",
    "                break\n",
    "\n",
    "        return job_links\n",
    "\n",
    "\n",
    "    def _æµè€é—†çš„è¯çµ¡(self, job_url):\n",
    "        self.driver.get(job_url)\n",
    "\n",
    "        WebDriverWait(self.driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"jobOrderTable\"]'))\n",
    "        )\n",
    "\n",
    "        page_source = self.driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        # æå–è¯çµ¡æ–¹å¼ä¸¦æª¢æŸ¥æ˜¯å¦æœ‰è¯çµ¡æ–¹å¼\n",
    "        contact_info = self._è¥¿æè€é—†çš„è¯çµ¡(soup.find('span', id=\"openupRemark\").text.strip() if soup.find('span', id=\"openupRemark\") else \"ç„¡è¯çµ¡æ–¹å¼\")\n",
    "        if contact_info == \"ç„¡è¯çµ¡æ–¹å¼\":\n",
    "            return None\n",
    "\n",
    "        # å¦‚æœæœ‰è¯çµ¡æ–¹å¼ï¼Œç¹¼çºŒæå–å…¶ä»–è³‡æ–™\n",
    "        job_details = {}\n",
    "        job_details['å…¬å¸åç¨±'] = soup.find('span', id=\"empName\").text.strip() if soup.find('span', id=\"empName\") else \"ç„¡å…¬å¸åç¨±\"\n",
    "        job_details['è·ä½'] = soup.find('span', id=\"jobTitle\").text.strip() if soup.find('span', id=\"jobTitle\") else \"ç„¡è·ä½\"\n",
    "        job_details['è¯çµ¡æ–¹å¼'] = contact_info\n",
    "\n",
    "\n",
    "        return f\"\"\"\n",
    "\n",
    "          ************************\n",
    "          {job_details['è¯çµ¡æ–¹å¼']}\n",
    "\n",
    "          å°Šæ•¬çš„{job_details['å…¬å¸åç¨±']}åŒäº‹ï¼Œæ‚¨å¥½ï¼Œ\n",
    "\n",
    "          æˆ‘æ˜¯åº·åŠ›äººåŠ›è³‡æºé¡§å•å…¬å¸çš„è«ä»”ã€‚\n",
    "\n",
    "          æ³¨æ„åˆ°è²´å…¬å¸æ­£åœ¨æ‹›è˜{job_details['è·ä½']}ï¼Œç‰¹æ­¤è¯ç¹«ï¼Œå¸Œæœ›ç‚ºè²´å¸æä¾›å°ˆæ¥­çš„äººåŠ›è³‡æºè§£æ±ºæ–¹æ¡ˆã€‚\n",
    "\n",
    "          ç…©è«‹æ‚¨å°‡æ­¤ä¿¡æ¯è½‰é”çµ¦è²´å…¬å¸çš„æ‹›è˜è² è²¬äººã€‚è‹¥åˆä½œæˆåŠŸï¼Œæˆ‘å€‘å°‡å‘æ‚¨æä¾›æ¯æœˆå¹³å‡$500çš„ä»‹ç´¹è²»ï¼ŒèŠè¡¨è¬æ„ã€‚\n",
    "\n",
    "          æ•¬ä¸Šï¼Œ\n",
    "          åº·åŠ›äººåŠ›è³‡æºé¡§å•å…¬å¸\n",
    "\n",
    "          ---\n",
    "\n",
    "          å°Šæ•¬çš„{job_details['å…¬å¸åç¨±']}ï¼Œæ‚¨å¥½ï¼Œ\n",
    "\n",
    "          \"\"\"\n",
    "\n",
    "\n",
    "    def _è¥¿æè€é—†çš„è¯çµ¡(self, contact_text):\n",
    "        # æå–é›»è©±è™Ÿç¢¼\n",
    "        phone_numbers = re.findall(r'\\b[456789]\\d{7}\\b', contact_text)\n",
    "        if phone_numbers:\n",
    "            return f'https://wa.me/{phone_numbers[0]}?text='\n",
    "            \n",
    "\n",
    "        # è‹¥ç„¡é›»è©±è™Ÿç¢¼å‰‡æå–é›»å­éƒµä»¶\n",
    "        email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', contact_text)\n",
    "        if email_match:\n",
    "            return email_match.group(0)\n",
    "\n",
    "        return \"ç„¡è¯çµ¡æ–¹å¼\"\n",
    "\n",
    "    def _åº·åŠ›æµè€é—†(self):\n",
    "        job_links = self._æµè¦è«‹äººçš„è€é—†()\n",
    "        allè€é—†çš„è¯çµ¡ = []\n",
    "\n",
    "        for link in job_links:\n",
    "            job_details = self._æµè€é—†çš„è¯çµ¡(link)\n",
    "            if job_details:  # åªæœ‰ç•¶æœ‰è¯çµ¡æ–¹å¼æ™‚æ‰åŠ å…¥åˆ—è¡¨\n",
    "                allè€é—†çš„è¯çµ¡.append(job_details)\n",
    "\n",
    "        # é—œé–‰ç€è¦½å™¨\n",
    "        self.driver.quit()\n",
    "\n",
    "        return allè€é—†çš„è¯çµ¡\n",
    "    ### æ‰¾è€é—† æ‰¾è€é—† æ‰¾è€é—† æ‰¾è€é—† æ‰¾è€é—† ### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Telegram boté…ç½®\n",
    "def _TGå¤šå·¥æ©Ÿå™¨äºº():\n",
    "    bot = telebot.TeleBot(userdata.get('tg2'))\n",
    "\n",
    "    ### èªªæ˜ /? ###\n",
    "    @bot.message_handler(commands=['?'])\n",
    "    def send_welcome(message):\n",
    "        bot.reply_to(message, \"\\\n",
    "        /$+å·¥ä½œå ä¾‹: /$åœ¨å®¶å·¥ä½œ \\n\\\n",
    "        [è³‡æ–™ä¾†æº:é¦™æ¸¯å‹å·¥è™•ã€careerjet.com.hk]\\n\\\n",
    "        \")\n",
    "        print('ğŸ³ğŸ³ğŸ³ æ­£åœ¨èªªæ˜ ğŸ³ğŸ³ğŸ³')\n",
    "\n",
    "    ### æœå°‹å·¥ä½œ /$åœ¨å®¶å·¥ä½œ ###\n",
    "    @bot.message_handler(func=lambda message: re.search(r'\\$', message.text))\n",
    "    def handle_dollar_sign_commands(message):\n",
    "        keyword = message.text.replace(\"/$\", \"\")\n",
    "        bot.reply_to(message, f\"æ­£åœ¨ç²å– {keyword} çš„å·¥ä½œè³‡æ–™...è«‹ç¨å€™...\")\n",
    "        print(f'ğŸ³ğŸ³ğŸ³ æ­£åœ¨ç²å– {keyword} çš„å·¥ä½œè³‡æ–™.. ğŸ³ğŸ³ğŸ³')\n",
    "\n",
    "        # ä½¿ç”¨ JobScraper é¡åˆ¥ä¾†ç²å–å·¥ä½œè³‡æ–™\n",
    "        scraper = JobScraper(keyword)\n",
    "        all_data = scraper.ç²å–æ‰€æœ‰å·¥ä½œè³‡æ–™()\n",
    "\n",
    "        _å›è¦†å°è©±(all_data,message)\n",
    "\n",
    "    ### æ‰¾è€é—†çš„è¯çµ¡ ###\n",
    "    @bot.message_handler(func=lambda message: re.search(r'\\â˜†', message.text))\n",
    "    def handle_dollar_sign_commands(message):\n",
    "        keyword = message.text.replace(\"\\â˜†\", \"\")\n",
    "        bot.reply_to(message, f\"ğŸ³ğŸ³ğŸ³ æ­£åœ¨ç²å–è¦æ‹›è˜ {keyword} çš„è€é—†...è«‹ç¨å€™... ğŸ³ğŸ³ğŸ³\")\n",
    "        print(f'ğŸ³ğŸ³ğŸ³ æ­£åœ¨ç²å–è¦æ‹›è˜ {keyword} çš„è€é—†.. ğŸ³ğŸ³ğŸ³')\n",
    "        # ä¾†æ‰¾è€é—†\n",
    "        scraper = JobScraper(keyword)\n",
    "        all_data = scraper._åº·åŠ›æµè€é—†()\n",
    "        _å›è¦†å°è©±(all_data,message)\n",
    "\n",
    "\n",
    "    ### allç”¨å›è¦† ###\n",
    "    def _å›è¦†å°è©±(å…§å®¹, msg):\n",
    "        # åˆ†å‰²æ¶ˆæ¯ï¼šå°‡æ¶ˆæ¯åˆ†å‰²æˆæ›´å°çš„å¡Šï¼Œæ¯å€‹å¡Šçš„é•·åº¦ä¸è¶…éTelegram APIçš„é™åˆ¶ï¼ˆ4096å­—ç¯€ï¼‰\n",
    "        MAX_MESSAGE_LENGTH = 4096\n",
    "        chunks = []\n",
    "        chunk = ''\n",
    "        for data in å…§å®¹:\n",
    "            if len(chunk) + len(data) + 1 < MAX_MESSAGE_LENGTH:\n",
    "                chunk += data + '\\n'\n",
    "            else:\n",
    "                chunks.append(chunk)\n",
    "                chunk = data + '\\n'\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        for chunk in chunks:\n",
    "            try:\n",
    "                bot.reply_to(msg, chunk)\n",
    "                time.sleep(1)  # æ¯ç™¼é€ä¸€å€‹è¨Šæ¯å¾Œç­‰å¾… 1 ç§’ï¼Œé¿å…è§¸ç™¼ API é™åˆ¶\n",
    "            except telebot.apihelper.ApiTelegramException as e:\n",
    "                if e.result_json['error_code'] == 429:\n",
    "                    retry_after = int(e.result_json['parameters']['retry_after'])\n",
    "                    print(f\"è§¸ç™¼ API é™åˆ¶ï¼Œéœ€ç­‰å¾… {retry_after} ç§’...\")\n",
    "                    time.sleep(retry_after)\n",
    "                    bot.reply_to(msg, chunk)\n",
    "                else:\n",
    "                    print(f\"ç™¼é€è¨Šæ¯æ™‚å‡ºç¾éŒ¯èª¤: {e}\")\n",
    "\n",
    "\n",
    "    print('$$$ TGå¤šå·¥æ©Ÿå™¨äººå·²åŸ·è¡Œ $$$')\n",
    "    bot.infinity_polling()\n",
    "\n",
    "# Telegram boté…ç½® \\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _TGå¤šå·¥æ©Ÿå™¨äºº()\n",
    "\n",
    "# 28 ç‰ˆ $$$$$$$$$$$$$$$$$$$$$$$$$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
